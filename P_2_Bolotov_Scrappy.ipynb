{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практическая работа №2\n",
    "Базовые возможности Scrapy\n",
    "Болотов М.В. АСУ4-22-1м"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy startproject quotes_scraper                 # В командной строке для создания папки проекта\n",
    "cd C:\\Users\\79125\\quotes_scraper\\quotes_scraper    # Заходим в папку проекта  \n",
    "cd spiders                                         # Заходим в папку  \n",
    "echo. > quotes_spider.py                           # Создаём содержащий паука\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прописать в созданном файле содержащем паука (последний шаг в командной строке)\n",
    "# скрапинг цитат с веб-сайта, пример, цитата - автор\n",
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes_scraper\"                                               # Имя паука\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',                             # Сайт пример  \n",
    "    ]\n",
    "\n",
    "    def parse(self, response):                                            # Принимает объект response, который содержит скачанные данные страницы\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {                                                       # Селектор CSS для извлечения информации о цитатах\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('span small::text').get(),\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(href)').get()           # Наличие ссылки \"Next\" для перехода на следующую страницу\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes_scraper\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',                              # Добавление нескольких сайтов \n",
    "        'https://socratify.net/',                                          # сайт 2\n",
    "        'https://ru.citaty.net/'                                           # сайт 3\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        if 'quotes.toscrape.com' in response.url:\n",
    "            for quote in response.css('div.quote'):                        # Извлечение цитат и авторов с сайта примера\n",
    "                yield {\n",
    "                    'text': quote.css('span.text::text').get(),\n",
    "                    'author': quote.css('span small::text').get(),\n",
    "                }\n",
    "\n",
    "            next_page = response.css('li.next a::attr(href)').get()        # Переход на следующую страницу (если есть)\n",
    "            if next_page is not None:\n",
    "                yield response.follow(next_page, self.parse)\n",
    "\n",
    "        elif 'socratify.net' in response.url: \n",
    "            for quote in response.css('div.quote-block'):                  # Извлечение цитат и авторов с сайта 2\n",
    "                yield {\n",
    "                    'text': quote.css('div.quote::text').get(),\n",
    "                    'author': quote.css('div.author::text').get(),\n",
    "                }\n",
    "\n",
    "        elif 'citaty.net' in response.url:\n",
    "            for quote in response.css('div.quotes__item'):                 # Извлечение цитат и авторов с сайта 3  \n",
    "                yield {\n",
    "                    'text': quote.css('div.quotes__text::text').get(),\n",
    "                    'author': quote.css('div.quotes__author::text').get(),\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy crawl Max                  # В командной строке запуск паука Макс           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
